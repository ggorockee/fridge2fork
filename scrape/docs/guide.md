# 상세 사용자 가이드

이 문서는 `crawler.py` 스크립트의 상세한 사용법, 작동 방식, 문제 해결 방법을 안내합니다.

## 소개

`crawler.py`는 [만개의 레시피](https://www.10000recipe.com/recipe/list.html) 웹사이트에서 레시피 정보를 수집하기 위해 만들어진 Python 스크립트입니다. 현재 버전은 상위 5개의 레시피를 대상으로 정보를 수집하여 터미널에 출력합니다.

## 작동 방식

스크립트는 다음 두 단계로 작동합니다.

1.  **레시피 목록 수집**:
    -   먼저, `https://www.10000recipe.com/recipe/list.html` 페이지에 접속하여 전체 레시피 목록의 HTML을 가져옵니다.
    -   HTML에서 각 레시피의 상세 페이지로 연결되는 링크(URL)를 추출합니다. 현재는 상위 5개만 사용합니다.
    -   사이트 구조 변경에 대응하기 위해 두 종류의 CSS 선택자를 사용하여 링크를 찾습니다.

2.  **레시피 상세 정보 추출**:
    -   앞서 수집한 5개의 URL 각각에 대해 개별적으로 접속합니다.
    -   각 페이지에서 레시피의 **제목**, **재료**, **조리 순서**를 추출합니다.
    -   추출된 정보는 정해진 형식에 따라 터미널에 출력됩니다.

## 출력 형식

스크립트는 각 레시피 정보를 다음 형식으로 터미널에 출력합니다.

```
--- 1번째 레시피 ---
URL: https://www.10000recipe.com/recipe/6938...
제목: 돼지고기 김치찌개 황금레시피

[재료]
- 돼지고기 목살 300g
- 신김치 1/4포기
- ...

[조리 순서]
1. 돼지고기는 먹기 좋게 썰어주세요.
2. ...
==================================================
```

## 문제 해결 (Troubleshooting)

-   **"레시피 링크를 찾을 수 없습니다." 메시지가 표시되는 경우**:
    -   **원인**: `만개의 레시피` 웹사이트의 HTML 구조가 변경되어 스크립트가 레시피 링크를 찾지 못하는 경우입니다.
    -   **해결**: `crawler.py` 파일의 `get_recipe_links` 함수 내부에 있는 `soup.select(...)` 부분의 CSS 선택자를 웹사이트의 새 구조에 맞게 수정해야 합니다.

-   **"HTTP 요청 중 오류가 발생했습니다" 메시지가 표시되는 경우**:
    -   **원인**: 인터넷 연결 문제 또는 웹사이트 서버의 일시적인 문제일 수 있습니다.
    -   **해결**: 인터넷 연결을 확인하고 잠시 후 다시 시도해 보세요. 문제가 지속되면 방화벽 설정 등을 확인해야 할 수 있습니다.

## 커스터마이징

### 스크랩할 레시피 개수 변경하기

기본적으로 스크립트는 5개의 레시피를 수집합니다. 이 개수를 변경하려면 `crawler.py` 파일의 `get_recipe_links` 함수에서 `recipe_links[:5]` 부분을 원하는 숫자로 수정하세요.

예를 들어 10개를 수집하고 싶다면 `recipe_links[:10]`으로 변경합니다.
