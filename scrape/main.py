#!/usr/bin/env python3
"""
Fridge2Fork ë°ì´í„° ì²˜ë¦¬ ì• í”Œë¦¬ì¼€ì´ì…˜ (Kubernetes í™˜ê²½ ìµœì í™”)

ì£¼ìš” ê¸°ëŠ¥:
- CSV ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ë° ì •ê·œí™”
- ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ê´€ë¦¬
- ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° í†µê³„
- í—¬ìŠ¤ì²´í¬ ë° ìƒíƒœ í™•ì¸

í™˜ê²½ë³€ìˆ˜ë¡œ ì‹¤í–‰ ëª¨ë“œ ì œì–´:
- MODE: migrate, stats, health, verify (ê¸°ë³¸ê°’: migrate)
- MAX_RECORDS: ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œ ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)
- CHUNK_SIZE: ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸° (ê¸°ë³¸ê°’: 100)
"""
import asyncio
import os
import sys
from pathlib import Path
from typing import List, Dict
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # ì»¨í…Œì´ë„ˆ í™˜ê²½ì—ì„œëŠ” dotenv ì—†ì´ë„ ë™ì‘
    pass

from scripts.migrate_csv_data import CSVDataMigrator

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DataManagementSystem:
    """ë ˆì‹œí”¼ ë°ì´í„° ê´€ë¦¬ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.migrator = None

    async def initialize(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì´ˆê¸°í™”"""
        self.migrator = CSVDataMigrator()
        await self.migrator.initialize()

    async def validate_data_integrity(self) -> Dict:
        """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
        if not self.migrator:
            await self.initialize()

        async with self.migrator.async_session() as session:
            try:
                from sqlalchemy import text
            except ImportError:
                logger.error("SQLAlchemy not available")
                return {'error': 'Database not available'}

            # ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬ ì¿¼ë¦¬
            integrity_query = """
            SELECT
                -- ê¸°ë³¸ í†µê³„
                (SELECT COUNT(*) FROM recipes) as total_recipes,
                (SELECT COUNT(*) FROM ingredients) as total_ingredients,
                (SELECT COUNT(*) FROM recipe_ingredients) as total_relations,

                -- ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
                (SELECT COUNT(*) FROM recipes WHERE rcp_ttl IS NULL OR rcp_ttl = '') as recipes_without_title,
                (SELECT COUNT(*) FROM ingredients WHERE name IS NULL OR name = '') as ingredients_without_name,
                (SELECT COUNT(*) FROM recipe_ingredients WHERE quantity_text IS NULL) as relations_without_quantity,

                -- ì™¸ë˜í‚¤ ë¬´ê²°ì„± ê²€ì‚¬
                (SELECT COUNT(*) FROM recipe_ingredients ri
                 LEFT JOIN recipes r ON ri.rcp_sno = r.rcp_sno
                 WHERE r.rcp_sno IS NULL) as orphaned_recipe_relations,
                (SELECT COUNT(*) FROM recipe_ingredients ri
                 LEFT JOIN ingredients i ON ri.ingredient_id = i.id
                 WHERE i.id IS NULL) as orphaned_ingredient_relations,

                -- ì¤‘ë³µ ë°ì´í„° ê²€ì‚¬
                (SELECT COUNT(*) - COUNT(DISTINCT name) FROM ingredients) as duplicate_ingredients,
                (SELECT COUNT(*) - COUNT(DISTINCT (rcp_sno, ingredient_id)) FROM recipe_ingredients) as duplicate_relations;
            """

            result = await session.execute(text(integrity_query))
            row = result.first()

            return {
                'basic_stats': {
                    'total_recipes': row.total_recipes,
                    'total_ingredients': row.total_ingredients,
                    'total_relations': row.total_relations
                },
                'data_quality': {
                    'recipes_without_title': row.recipes_without_title,
                    'ingredients_without_name': row.ingredients_without_name,
                    'relations_without_quantity': row.relations_without_quantity
                },
                'integrity_issues': {
                    'orphaned_recipe_relations': row.orphaned_recipe_relations,
                    'orphaned_ingredient_relations': row.orphaned_ingredient_relations,
                    'duplicate_ingredients': row.duplicate_ingredients,
                    'duplicate_relations': row.duplicate_relations
                }
            }

    async def analyze_ingredient_distribution(self) -> Dict:
        """ì¬ë£Œ ë¶„í¬ ë¶„ì„"""
        if not self.migrator:
            await self.initialize()

        async with self.migrator.async_session() as session:
            try:
                from sqlalchemy import text
            except ImportError:
                logger.error("SQLAlchemy not available")
                return {'error': 'Database not available'}

            # ì¬ë£Œ ë¶„í¬ ë¶„ì„ ì¿¼ë¦¬
            distribution_query = """
            SELECT
                -- ì¹´í…Œê³ ë¦¬ë³„ ì¬ë£Œ ë¶„í¬
                (SELECT json_agg(category_stats) FROM (
                    SELECT
                        COALESCE(category, 'unknown') as category,
                        COUNT(*) as ingredient_count
                    FROM ingredients
                    GROUP BY category
                    ORDER BY ingredient_count DESC
                ) category_stats) as category_distribution,

                -- ì¸ê¸° ì¬ë£Œ Top 20
                (SELECT json_agg(popular_ingredients) FROM (
                    SELECT
                        i.name,
                        i.category,
                        COUNT(ri.rcp_sno) as usage_count,
                        COUNT(CASE WHEN ri.importance = 'essential' THEN 1 END) as essential_count
                    FROM ingredients i
                    JOIN recipe_ingredients ri ON i.id = ri.ingredient_id
                    GROUP BY i.id, i.name, i.category
                    ORDER BY usage_count DESC
                    LIMIT 20
                ) popular_ingredients) as top_ingredients,

                -- ë ˆì‹œí”¼ë‹¹ í‰ê·  ì¬ë£Œ ìˆ˜
                (SELECT AVG(ingredient_count) FROM (
                    SELECT COUNT(*) as ingredient_count
                    FROM recipe_ingredients
                    GROUP BY rcp_sno
                ) recipe_ingredient_counts) as avg_ingredients_per_recipe,

                -- ì¤‘ìš”ë„ë³„ ì¬ë£Œ ë¶„í¬
                (SELECT json_object_agg(importance, count) FROM (
                    SELECT
                        COALESCE(importance, 'normal') as importance,
                        COUNT(*) as count
                    FROM recipe_ingredients
                    GROUP BY importance
                ) importance_dist) as importance_distribution;
            """

            result = await session.execute(text(distribution_query))
            row = result.first()

            return {
                'category_distribution': row.category_distribution or [],
                'top_ingredients': row.top_ingredients or [],
                'avg_ingredients_per_recipe': float(row.avg_ingredients_per_recipe or 0),
                'importance_distribution': row.importance_distribution or {}
            }

    async def get_database_stats(self) -> Dict:
        """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ"""
        if not self.migrator:
            await self.initialize()

        async with self.migrator.async_session() as session:
            try:
                from sqlalchemy import text
            except ImportError:
                logger.error("SQLAlchemy not available")
                return {'error': 'Database not available'}

            stats_query = """
            SELECT
                (SELECT COUNT(*) FROM recipes) as total_recipes,
                (SELECT COUNT(*) FROM ingredients) as total_ingredients,
                (SELECT COUNT(*) FROM recipe_ingredients) as total_relations,
                (SELECT AVG(total_ing) FROM (
                    SELECT COUNT(*) as total_ing
                    FROM recipe_ingredients
                    GROUP BY rcp_sno
                ) sub) as avg_ingredients_per_recipe;
            """

            result = await session.execute(text(stats_query))
            row = result.first()

            return {
                'total_recipes': row.total_recipes,
                'total_ingredients': row.total_ingredients,
                'total_relations': row.total_relations,
                'avg_ingredients_per_recipe': round(float(row.avg_ingredients_per_recipe or 0), 2)
            }

    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.migrator:
            await self.migrator.cleanup()


def print_data_integrity_report(integrity_data: Dict):
    """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ê²°ê³¼ ì¶œë ¥"""
    if 'error' in integrity_data:
        print(f"âŒ ë¬´ê²°ì„± ê²€ì‚¬ ì‹¤íŒ¨: {integrity_data['error']}")
        return

    print("\nğŸ“Š ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ë³´ê³ ì„œ")
    print("=" * 60)

    # ê¸°ë³¸ í†µê³„
    stats = integrity_data['basic_stats']
    print(f"ğŸ“ˆ ê¸°ë³¸ í†µê³„:")
    print(f"   ì´ ë ˆì‹œí”¼: {stats['total_recipes']:,}ê°œ")
    print(f"   ì´ ì¬ë£Œ: {stats['total_ingredients']:,}ê°œ")
    print(f"   ì´ ê´€ê³„: {stats['total_relations']:,}ê°œ")

    # ë°ì´í„° í’ˆì§ˆ
    quality = integrity_data['data_quality']
    print(f"\nğŸ” ë°ì´í„° í’ˆì§ˆ:")
    print(f"   ì œëª© ì—†ëŠ” ë ˆì‹œí”¼: {quality['recipes_without_title']:,}ê°œ")
    print(f"   ì´ë¦„ ì—†ëŠ” ì¬ë£Œ: {quality['ingredients_without_name']:,}ê°œ")
    print(f"   ìˆ˜ëŸ‰ ì—†ëŠ” ê´€ê³„: {quality['relations_without_quantity']:,}ê°œ")

    # ë¬´ê²°ì„± ë¬¸ì œ
    issues = integrity_data['integrity_issues']
    print(f"\nâš ï¸ ë¬´ê²°ì„± ë¬¸ì œ:")
    print(f"   ê³ ì•„ ë ˆì‹œí”¼ ê´€ê³„: {issues['orphaned_recipe_relations']:,}ê°œ")
    print(f"   ê³ ì•„ ì¬ë£Œ ê´€ê³„: {issues['orphaned_ingredient_relations']:,}ê°œ")
    print(f"   ì¤‘ë³µ ì¬ë£Œ: {issues['duplicate_ingredients']:,}ê°œ")
    print(f"   ì¤‘ë³µ ê´€ê³„: {issues['duplicate_relations']:,}ê°œ")

    # ì¢…í•© í‰ê°€
    total_issues = sum(issues.values()) + sum(quality.values())
    if total_issues == 0:
        print("\nâœ… ëª¨ë“  ë¬´ê²°ì„± ê²€ì‚¬ í†µê³¼!")
    else:
        print(f"\nâš ï¸ ì´ {total_issues:,}ê°œì˜ ë¬¸ì œ ë°œê²¬")


def print_ingredient_distribution(distribution_data: Dict):
    """ì¬ë£Œ ë¶„í¬ ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
    if 'error' in distribution_data:
        print(f"âŒ ë¶„í¬ ë¶„ì„ ì‹¤íŒ¨: {distribution_data['error']}")
        return

    print("\nğŸ“Š ì¬ë£Œ ë¶„í¬ ë¶„ì„ ë³´ê³ ì„œ")
    print("=" * 60)

    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
    if distribution_data['category_distribution']:
        print(f"\nğŸ“‚ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
        for category in distribution_data['category_distribution'][:10]:  # ìƒìœ„ 10ê°œë§Œ
            print(f"   {category['category']}: {category['ingredient_count']:,}ê°œ")

    # ì¸ê¸° ì¬ë£Œ
    if distribution_data['top_ingredients']:
        print(f"\nğŸ† ì¸ê¸° ì¬ë£Œ Top 10:")
        for i, ingredient in enumerate(distribution_data['top_ingredients'][:10], 1):
            category = ingredient['category'] or 'unknown'
            print(f"   {i:2d}. {ingredient['name']} ({category}): {ingredient['usage_count']:,}íšŒ ì‚¬ìš©")

    # í‰ê·  ì¬ë£Œ ìˆ˜
    avg_ingredients = distribution_data['avg_ingredients_per_recipe']
    print(f"\nğŸ“ˆ í‰ê·  ì¬ë£Œ ìˆ˜/ë ˆì‹œí”¼: {avg_ingredients:.1f}ê°œ")

    # ì¤‘ìš”ë„ ë¶„í¬
    if distribution_data['importance_distribution']:
        print(f"\nâ­ ì¤‘ìš”ë„ë³„ ë¶„í¬:")
        for importance, count in distribution_data['importance_distribution'].items():
            print(f"   {importance}: {count:,}ê°œ")


def print_database_stats(stats: Dict):
    """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¶œë ¥"""
    print("\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í†µê³„")
    print("=" * 40)
    print(f"ì´ ë ˆì‹œí”¼ ìˆ˜: {stats['total_recipes']:,}ê°œ")
    print(f"ì´ ì¬ë£Œ ìˆ˜: {stats['total_ingredients']:,}ê°œ")
    print(f"ë ˆì‹œí”¼-ì¬ë£Œ ì—°ê²°: {stats['total_relations']:,}ê°œ")
    print(f"í‰ê·  ì¬ë£Œ ìˆ˜/ë ˆì‹œí”¼: {stats['avg_ingredients_per_recipe']}ê°œ")


async def migrate_mode():
    """CSV ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ëª¨ë“œ"""
    logger.info("ğŸš€ CSV ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")

    max_records = int(os.getenv('MAX_RECORDS', '0')) or None
    chunk_size = int(os.getenv('CHUNK_SIZE', '100'))

    migrator = CSVDataMigrator(
        chunk_size=chunk_size,
        max_records=max_records
    )

    try:
        await migrator.initialize()

        # CSV íŒŒì¼ ì°¾ê¸°
        datas_dir = project_root / "datas"
        csv_files = sorted(datas_dir.glob("*.csv"))

        if not csv_files:
            logger.error("âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return 1

        # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
        for csv_file in csv_files:
            logger.info(f"ğŸ“„ {csv_file.name} ì²˜ë¦¬ ì¤‘...")
            await migrator.migrate_file(csv_file)

        # í†µê³„ ì¶œë ¥
        await migrator.print_statistics()
        logger.info("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        return 0

    except Exception as e:
        logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        return 1
    finally:
        await migrator.cleanup()


async def verify_mode():
    """ë°ì´í„° ê²€ì¦ ëª¨ë“œ"""
    logger.info("ğŸ” ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì‹œì‘")

    system = DataManagementSystem()
    try:
        await system.initialize()

        # ë¬´ê²°ì„± ê²€ì¦
        integrity_data = await system.validate_data_integrity()
        print_data_integrity_report(integrity_data)

        # ì¬ë£Œ ë¶„í¬ ë¶„ì„
        distribution_data = await system.analyze_ingredient_distribution()
        print_ingredient_distribution(distribution_data)

        return 0

    except Exception as e:
        logger.error(f"âŒ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return 1
    finally:
        await system.cleanup()


async def stats_mode():
    """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ëª¨ë“œ"""
    system = DataManagementSystem()
    try:
        await system.initialize()
        stats = await system.get_database_stats()
        print_database_stats(stats)
        return 0
    except Exception as e:
        logger.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return 1
    finally:
        await system.cleanup()


async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    try:
        system = DataManagementSystem()
        await system.initialize()
        stats = await system.get_database_stats()
        await system.cleanup()

        if 'error' in stats:
            logger.error("âŒ í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨")
            return 1

        logger.info("âœ… í—¬ìŠ¤ ì²´í¬ ì„±ê³µ")
        return 0
    except Exception as e:
        logger.error(f"âŒ í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {e}")
        return 1


async def maintenance_mode():
    """ìœ ì§€ë³´ìˆ˜ ëª¨ë“œ (ì»¨í…Œì´ë„ˆ ìœ ì§€ìš©)"""
    logger.info("ğŸ”§ ìœ ì§€ë³´ìˆ˜ ëª¨ë“œ ì‹œì‘")
    logger.info("â„¹ï¸ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ, ì»¨í…Œì´ë„ˆ ìœ ì§€ ì¤‘...")

    # í—¬ìŠ¤ ì²´í¬ë§Œ ìˆ˜í–‰í•˜ê³  ëŒ€ê¸°
    health_result = await health_check()
    if health_result != 0:
        return health_result

    # ë¬´í•œ ëŒ€ê¸° (Kubernetesì—ì„œ ì»¨í…Œì´ë„ˆ ìœ ì§€ìš©)
    try:
        while True:
            await asyncio.sleep(300)  # 5ë¶„ë§ˆë‹¤ ë¡œê·¸
            logger.info("ğŸ’“ ë°ì´í„° ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘...")
    except KeyboardInterrupt:
        logger.info("âš ï¸ ìœ ì§€ë³´ìˆ˜ ëª¨ë“œ ì¢…ë£Œ")
        return 0


def print_usage():
    """ì‚¬ìš©ë²• ì¶œë ¥ (DB ì—°ê²° ì—†ì´ ì‹¤í–‰ ê°€ëŠ¥)"""
    print("\nğŸ½ï¸ Fridge2Fork ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ")
    print("=" * 50)
    print("CSV ë°ì´í„°ë¥¼ PostgreSQLë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ë„êµ¬")
    print()
    print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“œ:")
    print("  migrate     - CSV ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰")
    print("  verify      - ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦")
    print("  stats       - ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ")
    print("  health      - í—¬ìŠ¤ ì²´í¬")
    print("  maintenance - ìœ ì§€ë³´ìˆ˜ ëª¨ë“œ (ì»¨í…Œì´ë„ˆ ìœ ì§€)")
    print("  help        - ì´ ë„ì›€ë§ í‘œì‹œ")
    print()
    print("ğŸ”§ í™˜ê²½ë³€ìˆ˜:")
    print("  MODE         - ì‹¤í–‰ ëª¨ë“œ (ê¸°ë³¸ê°’: migrate)")
    print("  MAX_RECORDS  - ìµœëŒ€ ì²˜ë¦¬ ë ˆì½”ë“œ ìˆ˜ (0=ì „ì²´)")
    print("  CHUNK_SIZE   - ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸° (ê¸°ë³¸ê°’: 100)")
    print()
    print("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •:")
    print("  DATABASE_URL - ì™„ì „í•œ PostgreSQL URL")
    print("  ë˜ëŠ” ê°œë³„ ì„¤ì •:")
    print("    POSTGRES_SERVER   - ì„œë²„ ì£¼ì†Œ")
    print("    POSTGRES_PORT     - í¬íŠ¸ (ê¸°ë³¸ê°’: 5432)")
    print("    POSTGRES_DB       - ë°ì´í„°ë² ì´ìŠ¤ëª…")
    print("    POSTGRES_USER     - ì‚¬ìš©ìëª…")
    print("    POSTGRES_PASSWORD - ë¹„ë°€ë²ˆí˜¸")
    print()
    print("ğŸ“ ì‚¬ìš© ì˜ˆì‹œ:")
    print("  # ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜")
    print("  MODE=migrate python main.py")
    print()
    print("  # í…ŒìŠ¤íŠ¸ìš© (1000ê°œë§Œ)")
    print("  MODE=migrate MAX_RECORDS=1000 python main.py")
    print()
    print("  # í†µê³„ í™•ì¸")
    print("  MODE=stats python main.py")
    print()

async def main():
    """ë©”ì¸ í•¨ìˆ˜ - í™˜ê²½ë³€ìˆ˜ë¡œ ëª¨ë“œ ê²°ì •"""
    mode = os.getenv('MODE', 'migrate').lower()

    # ë„ì›€ë§ ëª¨ë“œëŠ” DB ì—°ê²° ì—†ì´ ì‹¤í–‰
    if mode in ['help', '--help', '-h']:
        print_usage()
        return 0

    logger.info(f"ğŸ¯ ì‹¤í–‰ ëª¨ë“œ: {mode}")

    mode_map = {
        'migrate': migrate_mode,
        'verify': verify_mode,
        'stats': stats_mode,
        'health': health_check,
        'maintenance': maintenance_mode
    }

    if mode in mode_map:
        return await mode_map[mode]()
    else:
        logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œ: {mode}")
        print_usage()
        return 1


if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ğŸš¨ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        sys.exit(1)