#!/usr/bin/env python3
"""
CSV íŒŒì¼ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸


Usage:
    python scripts/analyze_csv.py

CSV íŒŒì¼ì˜ êµ¬ì¡°, ì¸ì½”ë”©, ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
"""
import pandas as pd
import chardet
from pathlib import Path
import sys


def detect_encoding(file_path):
    """íŒŒì¼ì˜ ì¸ì½”ë”© ê°ì§€"""
    with open(file_path, 'rb') as f:
        raw_data = f.read(100000)  # ì²˜ìŒ 100KBë§Œ ì½ì–´ì„œ ì¸ì½”ë”© ê°ì§€
        result = chardet.detect(raw_data)
        return result['encoding']


def analyze_csv_file(file_path):
    """CSV íŒŒì¼ ë¶„ì„"""
    print(f"\n{'='*60}")
    print(f"ğŸ“„ íŒŒì¼: {file_path.name}")
    print(f"ğŸ“Š í¬ê¸°: {file_path.stat().st_size / 1024 / 1024:.2f} MB")

    # ì¸ì½”ë”© ê°ì§€
    encoding = detect_encoding(file_path)
    print(f"ğŸ”¤ ì¸ì½”ë”©: {encoding}")

    # ì¸ì½”ë”© ì‹œë„ ìˆœì„œ
    encodings_to_try = [encoding] if encoding else []
    encodings_to_try.extend(['EUC-KR', 'UTF-8', 'CP949', 'UTF-16'])

    df = None
    used_encoding = None

    for enc in encodings_to_try:
        try:
            df = pd.read_csv(file_path, encoding=enc, nrows=5)
            used_encoding = enc
            print(f"âœ… {enc} ì¸ì½”ë”©ìœ¼ë¡œ ì½ê¸° ì„±ê³µ")
            break
        except:
            continue

    if df is None:
        print(f"âŒ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì „ì²´ ë°ì´í„° ë¡œë“œ (í–‰ ìˆ˜ í™•ì¸ìš©)
    try:
        df_full = pd.read_csv(file_path, encoding=used_encoding)
        print(f"ğŸ“ ì´ í–‰ ìˆ˜: {len(df_full):,}")
        print(f"ğŸ“‹ ì´ ì»¬ëŸ¼ ìˆ˜: {len(df_full.columns)}")

        # ì»¬ëŸ¼ ì •ë³´
        print(f"\nğŸ“Š ì»¬ëŸ¼ ëª©ë¡:")
        for i, col in enumerate(df_full.columns, 1):
            # ê° ì»¬ëŸ¼ì˜ nullì´ ì•„ë‹Œ ê°’ ê°œìˆ˜
            non_null_count = df_full[col].notna().sum()
            null_pct = (1 - non_null_count / len(df_full)) * 100
            print(f"  {i:2d}. {col} ({df_full[col].dtype}) - NULL: {null_pct:.1f}%")

        # ìƒ˜í”Œ ë°ì´í„°
        print(f"\nğŸ“„ ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 3ê°œ í–‰):")
        print(df_full.head(3).to_string(index=False, max_colwidth=30))

        # ì¬ë£Œ ê´€ë ¨ ì»¬ëŸ¼ ë¶„ì„
        ingredient_cols = [col for col in df_full.columns if 'ì¬ë£Œ' in col or 'RCP_PARTS_DTLS' in col]
        if ingredient_cols:
            print(f"\nğŸ¥˜ ì¬ë£Œ ê´€ë ¨ ì»¬ëŸ¼ ë¶„ì„:")
            for col in ingredient_cols:
                print(f"\n  {col}:")
                # ì¬ë£Œ ìƒ˜í”Œ ì¶œë ¥
                sample_ingredients = df_full[col].dropna().head(3)
                for i, ing in enumerate(sample_ingredients, 1):
                    print(f"    ì˜ˆì‹œ {i}: {ing[:100]}...")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del df_full

    except Exception as e:
        print(f"âŒ ì „ì²´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì´ë™
    project_root = Path(__file__).parent.parent
    datas_dir = project_root / "datas"

    print("ğŸ” CSV íŒŒì¼ ë¶„ì„ ì‹œì‘")
    print(f"ğŸ“ ë””ë ‰í† ë¦¬: {datas_dir}")

    # CSV íŒŒì¼ ì°¾ê¸°
    csv_files = list(datas_dir.glob("TB_RECIPE_SEARCH*.csv"))

    if not csv_files:
        print("âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return 1

    print(f"ğŸ“Š ì°¾ì€ CSV íŒŒì¼: {len(csv_files)}ê°œ")

    # ê° íŒŒì¼ ë¶„ì„
    for csv_file in sorted(csv_files):
        try:
            analyze_csv_file(csv_file)
        except Exception as e:
            print(f"âŒ {csv_file.name} ë¶„ì„ ì‹¤íŒ¨: {e}")

    print(f"\n{'='*60}")
    print("âœ… CSV íŒŒì¼ ë¶„ì„ ì™„ë£Œ")

    return 0


if __name__ == "__main__":
    sys.exit(main())