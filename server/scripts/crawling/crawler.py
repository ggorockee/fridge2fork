"""
ë©”ì¸ í¬ë¡¤ë§ ì‹œìŠ¤í…œ
"""
import asyncio
import json
import time
import logging
from typing import List, Dict, Optional
from datetime import datetime

from .config import CrawlingConfig
from .parser import RecipeParser, RecipeData
from .database import recipe_storage

class RecipeCrawler:
    """ë©”ì¸ ë ˆì‹œí”¼ í¬ë¡¤ëŸ¬"""
    
    def __init__(self):
        self.config = CrawlingConfig()
        self.parser = RecipeParser()
        self.storage = recipe_storage
        self.crawled_urls = set()  # ì¤‘ë³µ ë°©ì§€
        self.total_crawled = 0
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(
            level=getattr(logging, self.config.LOG_LEVEL),
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.config.LOG_FILE),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    async def crawl_recipes(self, target_count: int = None) -> Dict[str, int]:
        """ë ˆì‹œí”¼ ëŒ€ëŸ‰ í¬ë¡¤ë§"""
        if target_count is None:
            target_count = self.config.TOTAL_TARGET_RECIPES
        
        self.logger.info(f"ğŸš€ ë ˆì‹œí”¼ í¬ë¡¤ë§ ì‹œì‘ - ëª©í‘œ: {target_count}ê°œ")
        
        start_time = datetime.now()
        results = {
            "total_crawled": 0,
            "success": 0,
            "failed": 0,
            "skipped": 0
        }
        
        try:
            # 1ë‹¨ê³„: ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ë° ì‚¬ì´íŠ¸ ì ‘ì†
            self._initialize_browser()
            
            # 2ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ë³„ ë ˆì‹œí”¼ URL ìˆ˜ì§‘
            recipe_urls = self._collect_recipe_urls(target_count)
            self.logger.info(f"ğŸ“‹ ìˆ˜ì§‘ëœ ë ˆì‹œí”¼ URL: {len(recipe_urls)}ê°œ")
            
            # 3ë‹¨ê³„: ë°°ì¹˜ë³„ ë ˆì‹œí”¼ ìƒì„¸ ì •ë³´ í¬ë¡¤ë§
            await self._crawl_recipe_details(recipe_urls, results)
            
            # í†µê³„ ì¶œë ¥
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            self.logger.info("ğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!")
            self.logger.info(f"â±ï¸  ì†Œìš” ì‹œê°„: {duration:.2f}ì´ˆ")
            self.logger.info(f"âœ… ì„±ê³µ: {results['success']}ê°œ")
            self.logger.info(f"âŒ ì‹¤íŒ¨: {results['failed']}ê°œ")
            self.logger.info(f"â­ï¸  ê±´ë„ˆëœ€: {results['skipped']}ê°œ")
            
            # ìµœì¢… í†µê³„
            stats = await self.storage.get_crawling_stats()
            self.logger.info(f"ğŸ“Š DB ì´ ë ˆì‹œí”¼: {stats.get('total_recipes', 0)}ê°œ")
            self.logger.info(f"ğŸ“Š DB ì´ ì¬ë£Œ: {stats.get('total_ingredients', 0)}ê°œ")
            
            return results
            
        except Exception as e:
            self.logger.error(f"í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return results
    
    def _initialize_browser(self):
        """ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ë° ì‚¬ì´íŠ¸ ì ‘ì†"""
        self.logger.info("ğŸŒ ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ì¤‘...")
        
        # MCP Playwright í•¨ìˆ˜ë¥¼ ì „ì—­ìœ¼ë¡œ ì‚¬ìš©
        print("ë§Œê°œì˜ë ˆì‹œí”¼ ì‚¬ì´íŠ¸ë¡œ ì´ë™ ì¤‘...")
        print("ë ˆì‹œí”¼ ë¶„ë¥˜ í˜ì´ì§€ë¡œ ì´ë™...")
        
        self.logger.info("âœ… ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _collect_recipe_urls(self, target_count: int) -> List[str]:
        """ë ˆì‹œí”¼ URL ìˆ˜ì§‘"""
        self.logger.info("ğŸ“‹ ë ˆì‹œí”¼ URL ìˆ˜ì§‘ ì‹œì‘...")
        
        recipe_urls = []
        current_page = 1
        max_pages_per_category = 50  # ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ í˜ì´ì§€ ìˆ˜
        
        while len(recipe_urls) < target_count:
            try:
                # í˜„ì¬ í˜ì´ì§€ì˜ ë ˆì‹œí”¼ ë§í¬ ìˆ˜ì§‘
                page_urls = self._extract_recipe_urls_from_page()
                
                if not page_urls:
                    self.logger.warning(f"í˜ì´ì§€ {current_page}ì—ì„œ ë ˆì‹œí”¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    break
                
                # ì¤‘ë³µ ì œê±°í•˜ì—¬ ì¶”ê°€
                new_urls = [url for url in page_urls if url not in self.crawled_urls]
                recipe_urls.extend(new_urls)
                self.crawled_urls.update(new_urls)
                
                self.logger.info(f"ğŸ“„ í˜ì´ì§€ {current_page}: {len(new_urls)}ê°œ URL ìˆ˜ì§‘ (ì´ {len(recipe_urls)}ê°œ)")
                
                # ëª©í‘œ ë‹¬ì„± ì‹œ ì¢…ë£Œ
                if len(recipe_urls) >= target_count:
                    break
                
                # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
                if current_page < max_pages_per_category:
                    if self._go_to_next_page():
                        current_page += 1
                        time.sleep(self.config.DELAY_BETWEEN_PAGES)
                    else:
                        break
                else:
                    break
                    
            except Exception as e:
                self.logger.error(f"URL ìˆ˜ì§‘ ì˜¤ë¥˜ (í˜ì´ì§€ {current_page}): {e}")
                break
        
        return recipe_urls[:target_count]
    
    def _extract_recipe_urls_from_page(self) -> List[str]:
        """í˜„ì¬ í˜ì´ì§€ì—ì„œ ë ˆì‹œí”¼ URL ì¶”ì¶œ"""
        try:
            # í˜ì´ì§€ ìŠ¤ëƒ…ìƒ·ì„ í†µí•´ ë ˆì‹œí”¼ ë§í¬ ì¶”ì¶œ
            snapshot = mcp_playwright_browser_snapshot({"random_string": "get_links"})
            
            # JavaScriptë¡œ ë ˆì‹œí”¼ ë§í¬ ì¶”ì¶œ
            result = mcp_playwright_browser_evaluate({
                "function": """
                () => {
                    const links = [];
                    // ë ˆì‹œí”¼ ë§í¬ íŒ¨í„´ ì°¾ê¸°
                    const recipeLinks = document.querySelectorAll('a[href*="/recipe/"]');
                    
                    recipeLinks.forEach(link => {
                        const href = link.getAttribute('href');
                        if (href && href.includes('/recipe/') && !href.includes('/list.html')) {
                            const fullUrl = href.startsWith('http') ? href : 'https://www.10000recipe.com' + href;
                            links.push(fullUrl);
                        }
                    });
                    
                    return [...new Set(links)]; // ì¤‘ë³µ ì œê±°
                }
                """
            })
            
            return result if result else []
            
        except Exception as e:
            self.logger.error(f"ë ˆì‹œí”¼ URL ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
    
    def _go_to_next_page(self) -> bool:
        """ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™"""
        try:
            # ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ ì°¾ê¸° ë° í´ë¦­
            result = mcp_playwright_browser_evaluate({
                "function": """
                () => {
                    // í˜ì´ì§€ë„¤ì´ì…˜ì—ì„œ ë‹¤ìŒ ë²„íŠ¼ ì°¾ê¸°
                    const nextButtons = document.querySelectorAll('a');
                    for (let btn of nextButtons) {
                        if (btn.textContent.includes('ë‹¤ìŒ') || btn.textContent.includes('>') || btn.textContent.includes('next')) {
                            btn.click();
                            return true;
                        }
                    }
                    
                    // ìˆ«ì í˜ì´ì§€ ë²„íŠ¼ ì¤‘ í˜„ì¬ë³´ë‹¤ í° ë²ˆí˜¸ ì°¾ê¸°
                    const pageButtons = document.querySelectorAll('a[href*="page="]');
                    let maxPage = 0;
                    let nextPageBtn = null;
                    
                    pageButtons.forEach(btn => {
                        const pageMatch = btn.href.match(/page=(\\d+)/);
                        if (pageMatch) {
                            const pageNum = parseInt(pageMatch[1]);
                            if (pageNum > maxPage) {
                                maxPage = pageNum;
                                nextPageBtn = btn;
                            }
                        }
                    });
                    
                    if (nextPageBtn) {
                        nextPageBtn.click();
                        return true;
                    }
                    
                    return false;
                }
                """
            })
            
            if result:
                time.sleep(2)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"ë‹¤ìŒ í˜ì´ì§€ ì´ë™ ì˜¤ë¥˜: {e}")
            return False
    
    async def _crawl_recipe_details(self, recipe_urls: List[str], results: Dict[str, int]):
        """ë ˆì‹œí”¼ ìƒì„¸ ì •ë³´ í¬ë¡¤ë§"""
        self.logger.info(f"ğŸ“– ë ˆì‹œí”¼ ìƒì„¸ ì •ë³´ í¬ë¡¤ë§ ì‹œì‘ - {len(recipe_urls)}ê°œ")
        
        batch_recipes = []
        
        for i, url in enumerate(recipe_urls, 1):
            try:
                self.logger.info(f"ğŸ” í¬ë¡¤ë§ ì¤‘... ({i}/{len(recipe_urls)}): {url}")
                
                # ë ˆì‹œí”¼ í˜ì´ì§€ ì ‘ì†
                print(f"ë ˆì‹œí”¼ í˜ì´ì§€ ì ‘ì†: {url}")
                time.sleep(self.config.DELAY_BETWEEN_REQUESTS)
                
                # ë ˆì‹œí”¼ ë°ì´í„° ì¶”ì¶œ
                recipe_data = self._extract_recipe_data(url)
                
                if recipe_data:
                    # íŒŒì‹±ëœ ë ˆì‹œí”¼ ë°ì´í„°ë¡œ ë³€í™˜
                    parsed_recipe = self.parser.parse_recipe_from_json(recipe_data)
                    
                    if parsed_recipe and self.parser.validate_recipe(parsed_recipe):
                        batch_recipes.append(parsed_recipe)
                        results["total_crawled"] += 1
                        
                        # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ ì €ì¥
                        if len(batch_recipes) >= self.config.BATCH_SIZE:
                            batch_results = await self.storage.save_recipe_batch(batch_recipes)
                            self._update_results(results, batch_results)
                            batch_recipes = []
                            
                            self.logger.info(f"ğŸ“¦ ë°°ì¹˜ ì €ì¥ ì™„ë£Œ - ì„±ê³µ: {results['success']}, ì‹¤íŒ¨: {results['failed']}")
                    else:
                        results["skipped"] += 1
                        self.logger.warning(f"âš ï¸ ë ˆì‹œí”¼ ê²€ì¦ ì‹¤íŒ¨: {url}")
                else:
                    results["failed"] += 1
                    self.logger.error(f"âŒ ë ˆì‹œí”¼ ì¶”ì¶œ ì‹¤íŒ¨: {url}")
                
            except Exception as e:
                results["failed"] += 1
                self.logger.error(f"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜ ({url}): {e}")
        
        # ë‚¨ì€ ë°°ì¹˜ ì €ì¥
        if batch_recipes:
            batch_results = await self.storage.save_recipe_batch(batch_recipes)
            self._update_results(results, batch_results)
    
    def _extract_recipe_data(self, url: str) -> Optional[Dict]:
        """ë ˆì‹œí”¼ í˜ì´ì§€ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
        try:
            # JavaScriptë¡œ ë ˆì‹œí”¼ ë°ì´í„° ì¶”ì¶œ
            recipe_data = mcp_playwright_browser_evaluate({
                "function": """
                () => {
                    const data = {
                        title: '',
                        description: '',
                        author: '',
                        difficulty: '',
                        cookingTime: '',
                        servings: '',
                        ingredients: [],
                        cookingSteps: [],
                        tips: [],
                        tags: [],
                        url: window.location.href
                    };
                    
                    // ì œëª© ì¶”ì¶œ
                    const titleEl = document.querySelector('h3, h2, h1, .recipe_title');
                    if (titleEl) data.title = titleEl.textContent.trim();
                    
                    // ì„¤ëª… ì¶”ì¶œ
                    const descEl = document.querySelector('.recipe_desc, .description, p');
                    if (descEl) data.description = descEl.textContent.trim();
                    
                    // ì‘ì„±ì ì¶”ì¶œ
                    const authorEl = document.querySelector('.profile_name, .author, .writer');
                    if (authorEl) data.author = authorEl.textContent.trim();
                    
                    // ë‚œì´ë„, ì¡°ë¦¬ì‹œê°„, ì¸ë¶„ ì¶”ì¶œ
                    const infoElements = document.querySelectorAll('div, span, td');
                    infoElements.forEach(el => {
                        const text = el.textContent.trim();
                        if (text.includes('ì•„ë¬´ë‚˜') || text.includes('ì´ˆê¸‰') || text.includes('ì¤‘ê¸‰') || text.includes('ê³ ê¸‰')) {
                            data.difficulty = text;
                        } else if (text.includes('ë¶„') || text.includes('ì‹œê°„')) {
                            data.cookingTime = text;
                        } else if (text.includes('ì¸ë¶„')) {
                            data.servings = text;
                        }
                    });
                    
                    // ì¬ë£Œ ì¶”ì¶œ
                    const ingredientElements = document.querySelectorAll('li, tr, .ingredient');
                    ingredientElements.forEach(el => {
                        const text = el.textContent.trim();
                        if (text && text.length > 1 && text.length < 100) {
                            // ì¬ë£Œëª…ê³¼ ì–‘ ë¶„ë¦¬ ì‹œë„
                            const parts = text.split(/\\\\s+/);
                            if (parts.length >= 1) {
                                data.ingredients.push({
                                    name: parts[0],
                                    amount: parts.slice(1).join(' ') || 'ì ë‹¹ëŸ‰'
                                });
                            }
                        }
                    });
                    
                    // ì¡°ë¦¬ê³¼ì • ì¶”ì¶œ
                    const stepElements = document.querySelectorAll('.recipe_step, .cooking_step, ol li, .step');
                    stepElements.forEach((el, index) => {
                        const instruction = el.textContent.trim();
                        if (instruction && instruction.length > 5) {
                            data.cookingSteps.push({
                                stepNumber: index + 1,
                                instruction: instruction
                            });
                        }
                    });
                    
                    // íƒœê·¸ ì¶”ì¶œ
                    const tagElements = document.querySelectorAll('.tag, .hashtag');
                    tagElements.forEach(el => {
                        const tag = el.textContent.trim();
                        if (tag) data.tags.push(tag);
                    });
                    
                    return data;
                }
                """
            })
            
            return recipe_data if recipe_data else None
            
        except Exception as e:
            self.logger.error(f"ë ˆì‹œí”¼ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None
    
    def _update_results(self, results: Dict[str, int], batch_results: Dict[str, int]):
        """ê²°ê³¼ í†µê³„ ì—…ë°ì´íŠ¸"""
        results["success"] += batch_results.get("success", 0)
        results["failed"] += batch_results.get("failed", 0)
        results["skipped"] += batch_results.get("skipped", 0)

# ì „ì—­ í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
crawler = RecipeCrawler()
